# Copyright 2025 Snowflake Inc.
# SPDX-License-Identifier: Apache-2.0

"""
vLLM C++å¯¹è±¡çº§é”å®šé›†æˆ

ä¸€è¡Œæ›¿æ¢è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨çœŸæ­£çš„per-problem-IDå¹¶è¡Œ
"""

import time
from typing import List, Dict, Tuple, Any, Hashable

from .thread_safe_suffix_cache import ThreadSafeSuffixCache


def replace_vllm_suffix_prebuild_with_cpp_locking(
    vllm_rollout_instance,
    unique_problem_ids: List[Hashable],
    problem_id_to_sequences: Dict[Hashable, List[List[int]]],
    vllm_inputs: List[Dict],
    max_threads: int = None
) -> Dict[str, Any]:
    """
    ä½¿ç”¨C++å¯¹è±¡çº§é”å®šæ›¿æ¢vLLMä¸­çš„prebuildä»£ç 
    
    åœ¨vllm_rollout_spmd.pyä¸­æ›¿æ¢ç¬¬625-735è¡Œï¼š
    
    # åŸä»£ç ï¼ˆæœ‰é—®é¢˜çš„å¤šè¿›ç¨‹ç‰ˆæœ¬ï¼‰:
    # suffix_cache = self.inference_engine.llm_engine.model_executor.driver_worker.model_runner._suffix_cache
    # ... å¤æ‚çš„ã€æœ‰åºåˆ—åŒ–é—®é¢˜çš„å¤šè¿›ç¨‹ä»£ç  ...
    
    # æ›¿æ¢ä¸ºï¼š
    from arctic_inference.common.suffix_cache.vllm_cpp_locking_integration import replace_vllm_suffix_prebuild_with_cpp_locking
    result = replace_vllm_suffix_prebuild_with_cpp_locking(
        self, unique_problem_ids, problem_id_to_sequences, vllm_inputs
    )
    print(f"âœ… C++å¯¹è±¡çº§é”å®šå®Œæˆ: {result}")
    """
    
    if not unique_problem_ids or not problem_id_to_sequences:
        return {"total_problems": 0, "total_time": 0.0, "method": "cpp_locking_no_data"}
    
    # è·å–åŸå§‹SuffixCache
    original_suffix_cache = vllm_rollout_instance.inference_engine.llm_engine.model_executor.driver_worker.model_runner._suffix_cache
    max_depth = original_suffix_cache._max_depth
    
    # å‡†å¤‡æ•°æ®
    problems_data = []
    for problem_id in unique_problem_ids:
        if problem_id not in problem_id_to_sequences:
            continue
            
        prompt_tokens = vllm_rollout_instance.get_prompt_token_ids(vllm_inputs, problem_id)
        if prompt_tokens is None:
            continue
            
        sequences = problem_id_to_sequences[problem_id]
        if sequences:
            problems_data.append((problem_id, list(prompt_tokens), sequences))
    
    if not problems_data:
        return {"method": "cpp_locking", "total_problems": 0, "total_time": 0.0}
    
    print(f"ğŸš€ ä½¿ç”¨C++å¯¹è±¡çº§é”å®šå¤„ç†{len(problems_data)}ä¸ªproblems")
    
    # ä½¿ç”¨çº¿ç¨‹å®‰å…¨SuffixCache
    thread_safe_cache = ThreadSafeSuffixCache(
        max_depth=max_depth, 
        max_threads=max_threads or 8
    )
    
    # æ‰§è¡Œå¹¶è¡Œæ„å»º
    result = thread_safe_cache.build_problems_parallel(problems_data)
    
    # å°†ç»“æœåˆå¹¶åˆ°åŸå§‹SuffixCache
    print("åˆå¹¶ç»“æœåˆ°åŸå§‹SuffixCache...")
    merge_start = time.perf_counter()
    
    for problem_id in thread_safe_cache.main_cache._problem_tree:
        original_suffix_cache._problem_tree[problem_id] = thread_safe_cache.main_cache._problem_tree[problem_id]
    
    merge_time = time.perf_counter() - merge_start
    
    # æ›´æ–°ç»“æœç»Ÿè®¡
    result.update({
        "merge_time": merge_time,
        "original_cache_trees": len(original_suffix_cache._problem_tree)
    })
    
    print(f"âœ… C++å¯¹è±¡çº§é”å®šå®Œæˆ:")
    print(f"  æ–¹æ³•: çœŸæ­£çš„per-problem-IDå¹¶è¡Œ")
    print(f"  å¤„ç†é—®é¢˜æ•°: {result.get('successful_problems', 0)}")
    print(f"  å¹¶è¡Œæ—¶é—´: {result.get('parallel_time', 0.0):.4f}ç§’")
    print(f"  æ€»æ—¶é—´: {result.get('total_time', 0.0):.4f}ç§’")
    print(f"  åŠ é€Ÿæ¯”: {result.get('actual_speedup', 1.0):.2f}x")
    print(f"  ğŸ¯ è§£å†³äº†GILäº‰å¤ºå’Œåºåˆ—åŒ–é—®é¢˜")
    
    return result


def create_thread_safe_suffix_cache_replacement(
    original_suffix_cache,
    max_threads: int = None
):
    """
    åˆ›å»ºåŸSuffixCacheçš„çº¿ç¨‹å®‰å…¨æ›¿ä»£ç‰ˆæœ¬
    
    ä½¿ç”¨æ–¹æ³•ï¼š
    # åœ¨vLLMåˆå§‹åŒ–æ—¶æ›¿æ¢SuffixCache
    original_cache = self.inference_engine.llm_engine.model_executor.driver_worker.model_runner._suffix_cache
    thread_safe_cache = create_thread_safe_suffix_cache_replacement(original_cache)
    self.inference_engine.llm_engine.model_executor.driver_worker.model_runner._suffix_cache = thread_safe_cache
    """
    from .thread_safe_suffix_cache import ThreadSafeSuffixCacheAdapter
    
    return ThreadSafeSuffixCacheAdapter(
        max_depth=original_suffix_cache.max_depth,
        max_threads=max_threads
    )
